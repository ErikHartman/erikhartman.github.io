<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Synthetic biology; playing God, life or machine, bioterrorism and biotechnological singularities - a reason for urgency | Erik Hartman</title> <meta name="author" content="Erik Hartman"> <meta name="description" content="a longer article for SynthEthics"> <meta name="keywords" content="bioinformatics, machine learning, computational biology"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://erikhartman.github.io/blog/2019/sb/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?6185d15ea1982787ad7f435576553d64"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Erik </span>Hartman</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Synthetic biology; playing God, life or machine, bioterrorism and biotechnological singularities - a reason for urgency</h1> <p class="post-meta">January 1, 2019</p> <p class="post-tags"> <a href="/blog/2019"> <i class="fa-solid fa-calendar fa-sm"></i> 2019 </a>   ·   <a href="/blog/tag/synthetic"> <i class="fa-solid fa-hashtag fa-sm"></i> synthetic</a>   <a href="/blog/tag/biology"> <i class="fa-solid fa-hashtag fa-sm"></i> biology</a>   <a href="/blog/tag/ethics"> <i class="fa-solid fa-hashtag fa-sm"></i> ethics</a>   <a href="/blog/tag/philosophy"> <i class="fa-solid fa-hashtag fa-sm"></i> philosophy</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p><em>This was written in 2021 for an organization I created called Synthetics.</em></p> <h3 id="introduction">Introduction</h3> <p>Progress in biotechnology, synthetic biology and genetic engineering has pressed on into the modern era at an unfathomable pace, tantamount to the progress in computing (https://www.technologyreview.com/s/417628/a-moores-law-for-genetics/). It has surmounted in great achievements and the overcoming of tremendous challenges, although its use has been heavily restricted due to laws and regulations. These restrictions were a response to the surge of biotechnical advancement in the late 20th century, where too little time was spent investigating the consequences of state-of-the-art remedies, mostly in gene-therapy (https://geneticliteracyproject.org/2016/10/07/early-setbacks-gene-therapys-comeback-nearly-complete/) .</p> <p>Recent development in gene-editing has provided a new stomping ground for biotechnology to roam, resulting in local and global DIY-biohacking communities such as iGEM (https://igem.org/Main_Page). Exponential development within the fields has produced new methods of genetically engineering microbes, animals and plants, unlocking the gate for new applications, hitherto unknown organisms, and not to forget, a new field of science - synthetic biology. The field of synthetic biology has no generally accepted definition, however, for our purposes, we settle that:</p> <p>“Synthetic biology is the engineering of biology: the synthesis of complex, biologically based (or inspired) systems, which display functions that do not exist in nature. This engineering perspective may be applied at all levels of the hierarchy of biological structures—from individual molecules to whole cells, tissues and organisms. In essence, synthetic biology will enable the design of ‘biological systems’ in a rational and systematic way” (Synthetic Biology: Applying Engineering to Biology: Report of a NEST High Level Expert Group).</p> <p>It has become clear that the perceived sanctity of the blueprint of life - our genome, has been disturbed, and once we’ve fundamentally understood the genome of prokaryotic and eukaryotic cells and established standardized ways to edit them, it will dissipate. The recipe for life created by millions of years of evolution through natural selection will lay open to our interpretation and judgement, waiting to be improved. Practiced justly, synthetic biology and genetic engineering may solve many of the current global issues such as environmental deterioration, antibiotic resistance, and lack of global welfare - an opportunity we cannot afford to pass (frankly, one that would be unethical to pass) (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6692427/). Practiced maliciously, it may result in the abrupt demise of mankind. Needless to say, discriminating between these two outcomes should be seen as imperative and the time we spend on figuring out the contributing factors to either fallout is indispensable, yet the field isn’t receiving the attention it deserves in the public eye (Google searches for “AI ethics” and “Biotechnology ethics” receives 384 000 and 24 600 hits respectively).</p> <h3 id="ai-similarities">AI similarities</h3> <p>A similar field of science which has received the attention and ethical consideration it warrants is that of AI, with philosophers and scientists like Nick Bostrom, Max Tegmark, Sam Harris, Daniel Dennett and many more preaching its importance. Today, the field is well developed (it even has its own Wikipedia-page: https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence) and has reached a status of importance close to that of nuclear war in academic circles. AI is in its fetal stages of development, the equivalent of a mere eight-celled embryo, and once AI reaches a stage of iterated self-improvement beyond human understanding and control (a so-called singularity), the subsequent ethical considerations are worthless. Due to the explosive progressive nature of AI, philosophers and scientists have had to look decades and centuries into the future to observe and develop ethical inquiries. This has certainly required terrific determination and creativity on their part, and helpful tools have been created to aid their contemplation. I suggest that the progressive nature of AI is in many ways similar to that of biotechnology, an idea I will develop further later, and comparing the two fields may very well guide us in our quest for true north in the realm of bioethics.</p> <p>Natural selection was long the driving force for evolution through a process of trial-and-error. A gene may be randomly mutated, and if its function is impaired, and contributes to its host death, it will be discontinued. Natural selection was then overcome by human ingenuity, and the realization that offspring inherits traits from its parents. This gave way for artificial selection, where traits which were favoured by man were selected for. Today, scientific breakthroughs has broken all speed-records of evolution. By tampering with the genome of microbes, plants, animals and ourselves, we’re no longer limiting selection to certain traits nor are we limiting it to a certain pace. Once genetic enhancement begins in the realm of cognitive improvement, it will revamp our own ability to enhance itself (https://www.pewresearch.org/science/2016/07/26/human-enhancement-the-scientific-and-ethical-dimensions-of-striving-for-perfection/) At the point of view of evolution, living organisms has reached a state of singularity. Similar to how we won’t keep up with the unfathomable progress of an AI who reached the state of iterated self-improvement, natural selection will no longer keep up with us, for we have reached a state of such improvement. The singularity is further emphasized by the innate structure of biological systems and current research in biotechnology. One of the largest obstacles impeding progress today is the difficulty in cutting and pasting genes, and while the emergence of cut-and-paste-techniques like CRISPR-cas9 and prime editing accelerated advancement, both are far from perfect. As of now, there is a registry (iGEM registry https://igem.org/Registry) of 20 000 gene-parts (i.e. BioBricks) developed by researchers , but their use and compatibility is limited. Once universal scissors are created, which we can expect to happen in the 21th century, all combinations of parts and biological chassis will be available to us and the world will face a biotech-splosion - steepening the evolutionary singularity.</p> <p><img src="../img/synthethics-fig1.jpg" alt="fig"> Figure 1: The rate of evolution has fluctuated over time, but on a long time-scale it’s almost constant. Domestication of animals and crops increased the rate of evolution massively. Once genetic engineering is available, an evolutionary singularity is reached. The rate of evolution is similar to the rate of increase in computing power once iterated self-improvement is reached and when accounting for different timeframes.</p> <p>Why establishing a ethical ground is urgent Since the first living organism was brought into the world, natural selection has caused evolution. It has brought extinction upon those organisms unworthy of survival, and improved those on the brink of extinction. Blindly, it has favoured survival, nothing else. As of late, artificial selection - the trait-selection process made by man to enhance traits already present in plants or livestock, has dominated. As we move into an era of genetic engineering, none of these processes will dominate. Instead, man will be free to pick and choose novel traits, and to directly be the judge of what genes survive and which genes are to be discarded, and it is our responsibility to ensure a moral righteousness in our choices. Genetic modification may give rise to many immoral and riskful ventures, and as presented above, will occur rapidly. Therefore, as we strive towards enhancing microbes, plants, animals or humans, the consequences of our actions are heavily reliant on the moral status quo. There are more risks in need of ethical consideration than are currently regarded in the field of biotechnology, and as showcased above, these are urgent. The field of biotechnology should experience similar preparatory actions as those taken in the field of AI.</p> <h3 id="risk-philosophy">Risk philosophy</h3> <p>Technological advancement inherently brings the opportunity to act against the welfare of intelligent life. We can imagine the culmination of a positive moral outcome to rest on a knife’s edge, with almost all outcomes throwing it off balance. Most technological advancement increases the well-being of humans due to the fact that it counters existing misery, however, as we plug more holes of human hardship through advancement, the odds of producing technology with benefits outweighing the moral risks for malicious intent dwindles. Luckily, we’re far from having plugged all the holes of hardship, and the benefits of technological advancement generally grossly outweigh the entourage of risks. This analogy of steadily diminishing returns soon falls apart due to the large variation in dimensions of risks - if we ever encounter a risk so large that it proves detrimental to intelligent life, it tips the moral outcome too far from the knife’s edge. The implementation of large risks are elegantly exercised in the vulnerable world hypothesis (Bostrom, 2019). Here, all possible innovations, ideas and discoveries lie in an urn, in the form of balls, and the shade of the ball defines its risk for detrimental outcome. So far, we’ve drawn many white balls and only a few grey balls with low to moderate risks associated with them. However, when reaching down into the urn of innovation we’re always running the risk of picking a black ball - one that unfailingly results in the destruction of civilization. Diminishing returns can be implemented into the analogy by stating that the amount of balls in the urn is finite. As we draw a white ball, we subsequently increase the risk of drawing a black ball. When considering the advancement in biotechnology, we must constantly keep in mind the possibility of drawing a black ball, and we must, to the best of our ability, try to predict the shade of the ball before it’s drawn, because once a ball is drawn, it cannot be put back.</p> <h3 id="moral-failure">Moral failure</h3> <p>Moral risks are not as apparent as the ones of technological advancement. An innovation may be spawned from a context which we later recognize to be completely immoral, and we would be unable to determine the shade of the ball until our morality has shifted. Alternatively, an innovation may seem wholesome due to a prolonged immoral effect. This could be the case if an inherently harmless idea or innovation invariably leads to allowance of immoral behaviour which doesn’t align with our original intent. This could result in subsequent ruination as defined by Bostrom (2012): “Humanity reaches technological maturity in a way that gives good future prospects, yet subsequent developments cause the permanent ruination of those prospects.” All scenarios of moral risks can potentially be deterred, or at least marginalized, if we put effort into contemplating the possible scenarios and moral dilemmas we may face in the future, as done in the field of AI. Here, the problem of goal specification is notorious for needing thorough reflection before realisation. If we were to implement an unsound goal into an AI that has reached the point of singularity, the consequences would be disastrous. Prima facie the problem seems non-existent, but as one tries to define a goal it gets exceedingly difficult (imagine ordering an AI to make all humans happier (a seemingly benevolent goal), only to find all humans mindlessly plugged into a serotonin dispenser for eternity). This task faces many obstacles due to the inhuman nature of the receiving end, such as how to formulate a subjective objective in code, but the thought experiment results in dilemmas which are applicable once we face similar problems in the realm of biotechnology. Inter-cultural and inter-societal quarrels about the direction of progress is an issue we face as technology gets global interest, but who gets to decide where to go? This question is beyond the scope of this paper, but we should always keep the possibility of different points of view in the back of our head when contemplating morality. Although disputes complicate the practice of ethics, the moral landscape never changes, as argued by Sam Harris (and others). This implies that there is always an option in a moral quandary which is objectively and indisputably best, and finding this option is the goal of ethics.</p> <h3 id="moral-considerations">Moral considerations</h3> <p>The potential outcomes from development in biotechnology and genetic modifications are concealed from our current knowledge. Whatever the future may bring, we cannot comprehend it at this time due to the vast technological difference and the uncountable number of variations of outcomes. Not only are we unaware of what progress is to be done and which of the possible outcomes we can imagine will become reality but were also inevitably and necessarily completely unaware of most of those outcomes. The number of lifeforms, biological systems and molecules are nearly endlessly diverse - as beautifully showcased on earth by natural selection. To even imagine that we could fathom all future variations, artificially engineered or not, is ignorant. In fact, understanding evolution through genetic modification is far more hopeless than predicting traits selected for with natural or artificial selection, due to the unpredictable interplay between social, cultural and technological factors which affect the direction of progress and the expansion of the phenotypic arsenal. However, by applying general patterns and tendencies of human welfare to the progress of biotechnology one could assert in which direction we should point our nose, although the progress in human welfare would have to be weighed against the risks of technological advancement and the risk of moral failure. In 2011, Thomas Douglas and Julian Savulescu published an article about “Synthetic biology and the ethics of knowledge”, where they identified three concerns which most likely were to rise among bioethicists in the field of synthetic biology:</p> <p>“(1) concerns about ‘playing God’, which have been prominent in closely related areas of science (2) concerns about undermining the distinction between living things and machines, which attracted early attention from ethicists; and (3) concerns about the deliberate misuse of knowledge from synthetic biology”.</p> <p>They deemed (3) in most need of ethical analysis, and argued that (1) and (2) needn’t be subjects to deep contemplation. Disagreeing, I argue that as advancement in synthetic biology and biotechnology progresses, (1) and (2) will entail risk for moral deterioration and require thorough ethical consideration. Below, I begin dealing with the risk of technological advancement (1), to later move on to that of moral failure in (2) and (3) (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3045879/).</p> <p>Misuse of knowledge (3) Bioterrorism and scientific errors are two of the likely events which may culminate in an existential risk. An appropriate definition of existential risk is “one that threatens the premature extinction of Earth-originating intelligent life or the permanent and drastic destruction of its potential for desirable future development” (Bostrom, 2002). Noteworthy, an existential risk doesn’t only include extermination of intelligent life, but also the eradication of any possibility of future development. This would include the presence of a toxic wasteland as produced by nuclear war, but also the risk of pandemic plagues as produce of malicious intent or miscalculations in biotechnology. Miscalculations are not as uncommon as one may think, in fact, humanity has been on the brink of extinction as a consequence of scientific bloopers before. Famously, during the early years of nuclear trials, Edward Teller calculated that there was a small risk that the atomic bomb would ignite the atmosphere, resulting in an instant demolition of earth. The physicists of Los Alamos later realized that this would be highly unlikely. However, if this would have been the case, and the thought wouldn’t have struck Teller, we would all be dead, and we can consider ourselves lucky to not have been ignited 75 years ago. In the realm of biotechnology, an event similar to the Trinity nuclear test has already occurred. In 2011, a group of researchers wanted to showcase how the deadly H5N1-virus (popularly called the bird flu) could mutate to grow highly contagious. They did so by genetically modifying the virus to make it airborne - creating one of the most dangerous viruses known to man. Although the researchers tried to publish their work, the full articles were never released due to safety concerns (phew) (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3953619/ ). This blooper could easily have resulted in the death of a large proportion of our current population.</p> <p>With the near death scenario regarding the H5N1-virus in mind, we can easily envision a scenario where failure to predict or produce the sought-after functions of an altered organism results in peril. As the technical difficulties regarding the altering of genes subside as a result of technological advancement, the risk for mishaps like these grow. Consider what would happen if everyone had the possibility to produce a nuclear weapon in their garage, a scenario I think we’d all like to avoid. The number of crazed lunatics with access to such technology would surely result in the end of civilization as we know it - a black ball in the urn of innovations. It’s merely a luck of the draw that the creation of nuclear weapons require advanced facilities controlled by knowledgeable and trained personnel. One of the goals of biotechnological advancement is to increase the availability for DIY-biohacking and many of these facilities already exist. As a practitioner of synthetic biology who’s been teaching its principles to high-school students, I can assure you that the goal is increasingly attainable. Developing biological systems isn’t hard, it’s new, We can safely assume that if biohacking becomes available to everyone, including the psychotic hyper-paranoid lunatic who thinks the state has bugged his phone, we will face an existential risk. A grey ball could turn black if the requirements for the innovation is lessened and the risk of producing a black ball without appropriate consideration is alarmingly high.</p> <p><img src="../img/synthethics-fig2.jpg" alt="fig"> Figure 2: If research is left unregulated the likelihood for existential risks by bioterrorism or blunders increases with biotechnological advancement. As we reach the point of complete availability of DIY-biohacking we can ensure ourselves that bioterrorism or scientific blunders will result in an existential risk.</p> <h3 id="life-or-machine-2">Life or machine (2)</h3> <p>Most biotechnological efforts are conducted in the microscopic realm. Although invisible to the naked eye, microbes play an important role in our surroundings as well as in ourselves - their hosts. The effects our symbiotic companions entail are far more diverse than we previously thought, and many are still undiscovered. Coupling this with the fact that microbes are incredibly easy to engineer, and we’ve created a scientist’s playground. Microorganisms are miniature factories, constantly working in accordance with their genome and responding to their environment - which are under our control. Endeavours in synthetic biology are, by using engineering principles, resulting in programmable bacteria and novel proteins, controlled by complex switches which are implemented into their genome through manmade recombination. We’ve just received a malleable, programmable, fundamental and uniquely alive material that has been completely unused although it’s been around us since the origin of life. This opens up a completely new set of tools in the technological arsenal. Drew Endy, one of the founding fathers of synthetic biology stresses the use of biological organisms:</p> <p>“…I’ve got a pinetree in my front yard. It grows pinecones. I let them fall on the ground and throw them away. That’s crazy as an engineer. This is state of the art nanotechnology that manufactures itself every year.” (https://www.youtube.com/watch?v=8d-g2dDaZpU&amp;t=1954s) But are we mandated to modify living organisms to act as machines, factories, engineered to our benefit? Synthetic microorganisms fall in-between the life/non-life dichotomy, an, in many instances, lawless abode where companies and researchers make their own rules. These living yet lifeless organisms do not fall within our moral circle, and therefore, the life/machine-duality among them doesn’t affect us. However, if the rim of our moral circle expands beyond the world microbes - which some suggest it should (https://www.researchgate.net/publication/42793350_The_rights_of_microbes) - as a result of some scientific and philosophical breakthroughs, we would be victims to a prolonged immoral effect.</p> <h3 id="our-role-as-creators-1">Our role as Creators (1)</h3> <p>As our creative capacity grows within the field of biotechnology, the horizon of impossibility is pushed further away. Soon, modification will be passé, and only a middlehand to Creation - which is a defining constituent to the field of synthetic biology. In fact, such Creation was first conducted in 2010 when a bacterial genome was created from scratch, and inserted into a chassis bacteria - resulting in the first living organism with a completely synthetic genome (https://www.nature.com/news/2010/100520/full/news.2010.253.html). We can only expect that our capacities as Creators will expand. But how should we classify and treat our own Creations? How can we determine if they’re conscious, happy, or miserable? If we were to create a being which experiences terrible misery ever since the moment life is breathed into it, are we morally responsible for such agony? Should we treat the researchers who developed that organism with the same measures we would treat a criminal causing despair to another living being? If we were to measure our moral status quo in the amount of perceived well-being the world contains, a technology allowing for the mass production of miserable beings would be the epitome of moral blunders which would emphasize that (1) is a risk well worth our consideration (https://link.springer.com/article/10.1007%2Fs11948-012-9353-z). A similar ethical issue is raised within the world of AI. If we were to create conscious artificial intelligence, or mimic the human brain in a computer, we must consider our moral responsibility as Creators (Bostrom, Superintelligence 2014). As we ponder upon our moral obligations as Creators, we realize that it is essential to develop a deeper understanding of consciousness and life itself before we act. Moral responsibility is not only necessary in the extermination of life and the cause of misery - we’ve dealt with such responsibility for a long time and have a rough understanding of our modes of navigation - but also in the spawning and revision of life.</p> <h2 id="conclusion">Conclusion</h2> <p>New technology requires us to look into new rules of play, and when a technology revolves around tampering with biological life, the building blocks to the most sacred thing on earth, such rules have to be established before the game even begins. The game of biotechnology is definitively a game worth playing - the rewards are simply too large to ignore. Passivity is, like action, a decision which demands moral consideration. Further investigation regarding passivity versus action in the realm of biotechnology is required to know for certain whether we should continue our endeavours, however, I’m convinced action would come out victorious in such a debate. Although victorious, not without cost - with great reward comes great risk, and biotechnology is an exceptional case of high-risk technology. It may lead to our demise in an uncountable amount of ways and any skeptic would be hesitant towards our ascent up the mountains in the biotechnological landscape. Yet here we are, walking blindly towards the unknown. The least we can do, and are morally obligated to do, is to remove the blindfold - otherwise our chances of survival are terribly low. Therefore, we must engage in more serious risk-management regarding the spreading of biotechnological weapons, but we must also ponder upon how to conduct progress in a moral manner.</p> <p>Biological weapons are not the only threat we face, but one amongst many. During technological and moral advancement the seemingly simple questions have difficult answers. By playing God and by not differentiating between simple life and machines we run the risk of facing the worst moral deterioration possible. Technologies like AI and biotechnology are very similar in that they place responsibility in the hands of researchers and scientists and that they’re explosive in nature. This increases the risk for mishap and blunders. Luckily, organisations such as The Future of Life Institute and the Future of Humanity Institute are investigating which way to point our nose. Such progress is rapid in the field of AI, but the field of bioethics is currently underdeveloped. As we orient ourselves in the realm of bioethics we must pose questions like these, otherwise we might end up facing global catastrophe. Finding the true north is paramount to our survival and moral ground.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/bioterror/">Bioterrorism in light of SARS-Cov-2</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/sb-opp-risks/">Opportunities and risks of synthetic biology</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/probiotics/">A Brief History of Probiotics</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/markdown/">Writing academic articles in Markdown</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/displaying-external-posts-on-your-al-folio-blog/">Displaying External Posts on Your al-folio Blog</a> </li> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Erik Hartman. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?9b43d6e67ddc7c0855b1478ee4c48c2d" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>